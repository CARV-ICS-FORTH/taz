// Copyright 2022 Fabien Chaix
// SPDX-License-Identifier: LGPL-2.1-only

#ifndef _VEF_PARSER
#define _VEF_PARSER

#include "../Engine.hpp"
#include "../taz-simulate.hpp"
#include "AbstractParser.hpp"

struct VEFGroup : public AbstractGroup {
  std::vector<resind_t> cores;
  size_t num_msgs;
  // Information needed to depend on a message
  // index 0 is the send action, index 1 is the receive action
  std::vector<ActGroup> messages;
  int num_comms;
  size_t num_global_collectives;
  size_t num_local_collectives;
  // Information needed to enqueue and depend on a collective
  std::vector<int> collectives;
  bool active;
  std::string job_source;
  simtime_t start_time;
  double expected_duration;
  double compute_time_factor; // Multiply parsed values by this number
  size_t total_lines_to_parse;
  int job_id;
  EventHandleRef wall_handle;
  int n_lines_read;
  int epoch; // number of collectives since start
  resind_t node;
  std::ifstream::pos_type trace_start;
  std::shared_ptr<std::istream> file;
  ApproxMatrix mat;

  VEFGroup() {}

  virtual void init(int job_id_, commind_t world_comm, simtime_t start,
                    simtime_t wall, const std::vector<resind_t> &corev,
                    double compute_time_factor_, int n_iterations) {
    AbstractGroup::init(job_id_, world_comm, start, wall, cores,
                        compute_time_factor_, n_iterations);
    cores = corev;
    n_lines_read = 0;
    epoch = 0;
    file->clear();
    file->seekg(0);
    this->compute_time_factor = compute_time_factor_;
  }

  void finish(simtime_t time) {
    messages.clear();
    collectives.clear();
    AbstractGroup::finish(time);
  }
};

template <> struct HeapConsumer<VEFGroup> {
  static size_t get_heap_footprint(const VEFGroup &x) {
    size_t footprint = HeapConsumer<AbstractGroup>::get_heap_footprint(x);
    footprint += GET_HEAP_FOOTPRINT(x.cores);
    footprint += GET_HEAP_FOOTPRINT(x.messages);
    footprint += GET_HEAP_FOOTPRINT(x.collectives);
    footprint += GET_HEAP_FOOTPRINT(x.mat);
    return footprint;
  }
};

class VEFParser : public AbstractParser<VEFGroup>, protected GenericParser {

  enum class DepType { INDEPENDENT = 0, SEND, RECEIVE, COLLECTIVE };
  enum class CollectiveType {
    BROADCAST = 0,
    REDUCE,
    ALLREDUCE,
    GATHER,
    SCATTER,
    ALLGATHER,
    BARRIER,
    ALLTOALL
  };

  bool parse_line(VEFGroup &group, std::string &tmp);

  actind_t get_dep(VEFGroup &g, DepType type, const char *ptr);

public:
  VEFParser() : AbstractParser<VEFGroup>("VEFParser") {}

  virtual int get_or_create_trace_group(const char *trace_filename,
                                        const char *traffic_filename,

                                        int &number_of_traces);

  // Return if there are more events in the trace
  virtual bool parse();

  virtual const ApproxMatrix &get_traffic_matrix(size_t group_id) {
    assert(group_id < groups.size());
    return groups[group_id].mat;
  }

  virtual size_t get_footprint() {
    size_t footprint =
        AbstractParser<VEFGroup>::get_footprint() + sizeof(GenericParser);
    return footprint;
  }
};

/*

From
https://gitraap.i3a.info/fandujar/VEF-TraceLIB/-/blob/master/src/TraceManager.h

---------------------------------VEF Trace Format--------------------------

A VEF trace has three parts:

1) Trace Header. Contains basic information about the trace.
2) Communicators (COMMs). A COMM is a group of tasks that communicate in
   collective operation. The communicators specify collective communications.
   Tasks of the communicator are involved in the message exchange. One task can
use several COMMs to communicate with different tasks. 3) Trace Body. Contains
the messages generated by the task. There are two types of messages: 3.1) Those
corresponding to point-to-point communications 3.2) Those corresponding to
collective communications


 ****   HEADER format  *******

  VEF NumTask  NumMsg  NumCOMM  NumGlobalGroupComm NumLocalGroupComm
onlySendFlag

where:

NumTask      		--> Number of MPI tasks.
NumMsg	     		--> Number of point to point messages.
NumCOMM    		--> Number of communicators (COMM).
NumGlobalGroupComm 	--> Number of global collective communications.
NumLocalGroupComm 	--> Number of local collective communications. ie, a
4-task broadcast supposes one global collective communication and 4 local
collective communications.
onlySendFlag		--> True if all the
point-to-point message dependencies are send dependencies.

 ****   Communicator (COMM) format  *******
       id task_0 [task_1 ... task_N-1]

 * where
       id: COMM identifier. The id is composed by the letter "C" followed by a
natural number that identifies the COMM. task_0 [task_1 ... task_N-1] :
identifiers of the tasks involved in the COMM.

       ie, if the COMM id is 2, and the tasks involved in the communications are
the tasks 0, 1 ,2 y 3:

       C2 0 1 2 3


 ****   Point to Point Messages *******

       ID src dst tam Dep time IDdep

where:
ID      --> Message identifier. The identifier is unique for each message.
src     --> Source task.
dst     --> Destination task.
tam     --> Message size measured in bytes.
Dep     --> Dependency type.
time    --> Injection Time/dependency time in nanoseconds (depends on field
"Dep")
IDdep   --> -1 / Dependency Message Identifier (depends on field "Dep")

where "Dep" is:

* 0 : Independent Message: The message "ID" is sent at time "time". "IDdep" is
-1.
* 1 : Send Dependency:  The  message "ID" is sent "time" nanoseconds after
sending the message "IDdep".
* 2 : Receive dependency:  The message "ID" is sent "time" nanoseconds after
receiving the message "IDdep".
* 3 : Collective communication dependency: The message "ID" is sent "time"
nanoseconds after the task "task" has completed its participation in the
collective communication "IDdep". In this case, "IDdep" includes the letter "G"
before the numeric ID.


 ****   Collective communication Messages *******

       ID ID_COMM ID_OP task send_size recv_size Dep time IDdep
where:
ID      	--> Message identifier. In order to distinguish these messages
                   from point-to-point messages, the character "G" is included
                   before the ID number. This identifier is the same for all
records in the trace involved in the same global collective communication.
ID_COMM 	--> COMM identifier.
ID_OP   	--> Collective communication type.
task		--> Task identifier
send_size	--> Bytes sent by the current task.
recv_size	--> Bytes received by the current task.
Dep            --> Dependency type.
time           --> Injection Time/dependency time (depends on field "Dep")
IDdep          --> -1 / Dependency Message Identifier (depends on field "Dep")

The "Dep", "time" and "IDdep" fields take the same values than in the
point-to-point messages.
About ID_OP: (Note that "X" is the message size when all the messages generated
by the collective communication have the same size, as the Broadcast or Reduce.
In other case, as Gather or Scatter, "X_i" is the size of message sent or
received by the task "i", and SUM(X_i) is the summatory of all the messages sent
or received during the operation)

*  0: Broadcast. When the current task is the root: send_size=X,
recv_size=0; in other case, send_size=0, recv_size=X
*  1: Reduce.
       When the current task is the root: send_size=0, recv_size=X;
       in other case: send_size=X, recv_size=0
*  2: AllReduce.
       In this case, send_size=recv_size != 0
*  3: Gather.
       When the current task is the root: send_size=X_i, recv_size=SUM(X_i);
       in other case: send_size=X_i, recv_size=0
*  4: Scatter.
       When the current task is the root: send_size=SUM(X_i), recv_size=X_i;
       in other case: send_size=0, recv_size=X_i
*  5: Allgather.
       send_size=X_i, recv_size=SUM(X_i)
*  6: Barrier.
       send_size=recv_size=0
*  7: AlltoAll.
       when recv_size=0 Basic AlltoAll. The current task sends a message of
"send_size" bytes to each task.
       when recv_size=1 Vectorial AlltoAll. The current
task sends "send_size" bytes (split between all the task)
 */

#endif
